---
display: false
date: 2020-06-15
title:  抓取微信公众号内容
categories: [Python]
tags: [公众号, 爬虫]
draft: false
---

## 导语

我经常会集中阅读一些公众号内容，手机上看效率非常低，所以要将公众号整理成册子。

无论是手机还是电脑版的公众号，都对爬虫做了非常强的限制，主要体现在页面内容地址是算法生成的，没有固定的模式，还有过期限制。页面头部信息加入了一堆的计算和验证，基本上破解梳理完脑壳也就碎了一半。

也不是说完全无法解决，而是成本很高，如果不是商业规模化的应用，做公众号爬虫非常不划算。

## 现有方案

1. 纯代码爬取HTML硬钢腾讯
2. Android模拟器界面浏览，内部控件截取内容
3. Android模拟器或者PC端模拟浏览，截取https内容
4. 网上传的很多的吃搜狗的结果

第一种方式基本是脑裂模式，网上现有的代码早已失效不可用，从登陆、验证头部到获取内容，每一步都是深坑。

第二种方式可行，需要操控一些界面自动化程序，模拟进行窗口的下拉和浏览，触发内容时，从内部控件提供的方法内容。模拟器的使用有一定的门槛。

第三种方案是最简化的，编程工作主要体现在内容解析上，Python非常擅长。另外要解决的就是微信返回的内容是https，无论是android和电脑客户端都没办法直接保存为文件，这个步骤要引入https代理或者说中间人的程序。

加入代理后，公众号客户端请求全部发送给代理，代理发送给微信。代理可以解析和保存https的内容。

我们需要部署一个可以解密https的代理。

最后一种也可行，搜狗的搜索也是爬虫爬来的，我们也可以爬他的，问题是搜过也爬的不是很全，内容零散，支撑搜索结果还可以，如果要完整的公众号内容，质量就很差。

## 那种比较合适

像搜狗搜索引擎或者新榜这类公众号数据平台，我认为他们内部也没有全面的破解公众号爬虫。

腾讯对此的策略应该是半推半就，一方面将内容牢牢的锁死在微信内部生态圈，另一方面加高门槛，留一些口子给外部用，达到传播的目的。现在公众号发文连外部链接都不给用，就知道内容生态构建有多强势。

回归我们的方案，通过搭建代理程序捕捉https流量，Python解析流量文本就可以获取完整的公众号内容。

这其中第一步骤的浏览这个动作，我们手动执行，不再开发自动脚本，对于小规模非频繁的抓取，成本很低。如果是想搭建一个新榜类型的网站，择可以进一步开发。

## 具体实现

### 安装Chalers

市面上有其他替代，我们选取最容易用的一个Chalers。

1. 设置启用ssl加密。
1. 打开mirror镜像功能将内容保存到文件
2. 设置mirror中要镜像的链接前缀
3. 打开微信电脑客户端浏览下公众号，可以获取到链接域名前缀

### 浏览公众号

1. 开启Chalers内容捕捉
2. 人工浏览公众号，在列表页面，下拉获取所有的列表
3. 关闭Chalers
4. 检查mirror生成的文件

### 提取公众号链接

用Python脚本来解析公众号内容，我们只关注标题、时间、正文链接content_url这三个东西。

将之存到单独的文本文件中，避免后续进程失败每次都要运行。

### 提取正文
然后调用requests单独下载这个url链接的列表，为了记录下载进度，把保存好的地址可以在放进一个文件中，下载前比对一次。

微信返回的正文不是纯json格式，是一种混合模式，有些value本身是string，需要进一步的decode。

选用demjson这个库，来宽泛的匹配和加载json。

微信的正文结构其实是很糟糕的，设计师肯定不是一个像多数设计一样的有洁癖的人，内容是内联html样式。也就是早期互联网繁荣时，大众常用的样式方法，将无数一堆的样式表放到html正文，同时正文又层叠了一些自定义的样式，实用第一，最终显示非常风骚，但看源码脑裂。

也不是不好，最大的问题是单张网页内容过大。

我们用tomd这个库将html转为精简的md格式，目前没有太完美的库，但从结果来看基本达到。

自定一些替换词，进一步删除无用的信息。文件大小缩减到五分之一还小，表现上更简洁、突出内容本身。

### 打包
可以用pandoc或者readthedoc自动生成pdf和epub格式。


## 尾声

微信公众号平台对爬虫做了限制，就个人应用来说，用Chalers手动抓包，Python自动解包和下载文章的方式性价比最高。

